{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-15T18:38:02.291417Z","iopub.status.busy":"2023-04-15T18:38:02.290520Z","iopub.status.idle":"2023-04-15T18:38:14.874702Z","shell.execute_reply":"2023-04-15T18:38:14.873656Z","shell.execute_reply.started":"2023-04-15T18:38:02.291371Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset, SubsetRandomSampler\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","import wandb\n","import random\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:38:14.877960Z","iopub.status.busy":"2023-04-15T18:38:14.876864Z","iopub.status.idle":"2023-04-15T18:38:18.082352Z","shell.execute_reply":"2023-04-15T18:38:18.081060Z","shell.execute_reply.started":"2023-04-15T18:38:14.877922Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"questgen_key\")\n","wandb.login(key=secret_value_0)"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:38:18.090478Z","iopub.status.busy":"2023-04-15T18:38:18.087623Z","iopub.status.idle":"2023-04-15T18:38:18.097393Z","shell.execute_reply":"2023-04-15T18:38:18.096152Z","shell.execute_reply.started":"2023-04-15T18:38:18.090433Z"},"trusted":true},"outputs":[],"source":["# ASK_TOKEN = '<ASK>'\n","# COMPLETE_TOKEN = '<COMPLETE>'\n","# SUM_TOKEN = '<SUM>'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:38:18.100324Z","iopub.status.busy":"2023-04-15T18:38:18.099370Z","iopub.status.idle":"2023-04-15T18:38:18.111933Z","shell.execute_reply":"2023-04-15T18:38:18.110643Z","shell.execute_reply.started":"2023-04-15T18:38:18.100284Z"},"trusted":true},"outputs":[],"source":["class SquadDataset(Dataset):\n","    def __init__(self, split, tokenizer, task_num=0):\n","        self.split = split\n","        self.tokenizer = tokenizer\n","        self.tn = task_num\n","        self.squad_dataset = load_dataset('squad')[split]\n","        \n","    def __len__(self):\n","        return len(self.squad_dataset)\n","    \n","    def __getitem__(self, idx):\n","        example = self.squad_dataset[idx]\n","        \n","        input_text = example['context']\n","        target_text = f\"question: {example['question']} answer: {example['answers']['text'][0]}\"\n","        \n","        input_encoding = self.tokenizer(input_text, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n","        target_encoding = self.tokenizer(target_text, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n","        \n","        input_ids = input_encoding['input_ids'].squeeze()\n","        target_ids = target_encoding['input_ids'].squeeze()\n","        \n","        return {\n","            'input_ids': input_ids,\n","            'target_ids': target_ids,\n","            'task': self.tn\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:38:18.117455Z","iopub.status.busy":"2023-04-15T18:38:18.116583Z","iopub.status.idle":"2023-04-15T18:38:18.129484Z","shell.execute_reply":"2023-04-15T18:38:18.128337Z","shell.execute_reply.started":"2023-04-15T18:38:18.117417Z"},"trusted":true},"outputs":[],"source":["class RaceDataset(Dataset):\n","    def __init__(self, split, tokenizer, task_num=1):\n","        self.split = split\n","        self.tokenizer = tokenizer\n","        self.tn = task_num\n","        self.race_dataset = load_dataset('race', 'all')[split]\n","        self.race_dataset = self.race_dataset.filter(\n","            lambda example: '?' not in example['question'])\n","        self.mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n","        \n","    def __len__(self):\n","        return len(self.race_dataset)\n","    \n","    def __getitem__(self, idx):\n","        example = self.race_dataset[idx]\n","                \n","        input_text = example['article']\n","        ans = example['options'][self.mapping[example['answer']]]\n","        target_text = f\"question: {example['question']} answer: {ans}\"\n","        \n","        input_encoding = self.tokenizer(input_text, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n","        target_encoding = self.tokenizer(target_text, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n","        \n","        input_ids = input_encoding['input_ids'].squeeze()\n","        target_ids = target_encoding['input_ids'].squeeze()\n","        \n","        return {\n","            'input_ids': input_ids,\n","            'target_ids': target_ids,\n","            'task': self.tn\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:38:18.132064Z","iopub.status.busy":"2023-04-15T18:38:18.131300Z","iopub.status.idle":"2023-04-15T18:38:18.142813Z","shell.execute_reply":"2023-04-15T18:38:18.141652Z","shell.execute_reply.started":"2023-04-15T18:38:18.132020Z"},"trusted":true},"outputs":[],"source":["class BillsumDataset(Dataset):\n","    def __init__(self, split, tokenizer, task_num=2):\n","        self.split = split\n","        self.tokenizer = tokenizer\n","        self.tn = task_num\n","        self.billsum_dataset = load_dataset('billsum')[split]\n","        \n","    def __len__(self):\n","        return len(self.billsum_dataset)\n","    \n","    def __getitem__(self, idx):\n","        example = self.billsum_dataset[idx]\n","        \n","        input_text = example['text']\n","        target_text = example['summary']\n","        \n","        input_encoding = self.tokenizer(input_text, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n","        target_encoding = self.tokenizer(target_text, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n","        \n","        input_ids = input_encoding['input_ids'].squeeze()\n","        target_ids = target_encoding['input_ids'].squeeze()\n","        \n","        return {\n","            'input_ids': input_ids,\n","            'target_ids': target_ids,\n","            'task': self.tn\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:38:18.158518Z","iopub.status.busy":"2023-04-15T18:38:18.157698Z","iopub.status.idle":"2023-04-15T18:38:18.170092Z","shell.execute_reply":"2023-04-15T18:38:18.168979Z","shell.execute_reply.started":"2023-04-15T18:38:18.158423Z"},"trusted":true},"outputs":[],"source":["class CircularDataLoader:\n","    def __init__(self, datasets, batch_size, **kwargs):\n","        self.dataset_loaders = [DataLoader(ds, batch_size=batch_size, **kwargs)\n","                                for ds in datasets]\n","        self.iters = [iter(dl) for dl in self.dataset_loaders]\n","        self.num_datasets = len(datasets)\n","        self.current_idx = 0\n","    \n","    def _next_loader(self):\n","        if self.current_idx < len(self.iters) - 1:\n","            self.current_idx += 1\n","        else:\n","            self.current_idx = 0\n","    \n","    def __iter__(self):\n","        return self\n","        \n","    def __next__(self):\n","        got = False\n","        while not got and self.iters:\n","            try:\n","                batch = next(self.iters[self.current_idx])\n","                got = True\n","            except StopIteration:\n","                del self.iters[self.current_idx]\n","                self._next_loader()\n","        \n","        if not self.iters:\n","            raise StopIteration\n","        self._next_loader()\n","        return batch\n","\n","    def __len__(self):\n","        return sum(len(dl) for dl in self.dataset_loaders)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:38:18.172598Z","iopub.status.busy":"2023-04-15T18:38:18.171919Z","iopub.status.idle":"2023-04-15T18:38:21.444138Z","shell.execute_reply":"2023-04-15T18:38:21.443045Z","shell.execute_reply.started":"2023-04-15T18:38:18.172528Z"},"trusted":true},"outputs":[],"source":["tokenizer = T5Tokenizer.from_pretrained('t5-small')\n","# tokenizer.add_tokens(ASK_TOKEN)\n","# tokenizer.add_tokens(COMPLETE_TOKEN)\n","# tokenizer.add_tokens(SUM_TOKEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:38:21.451400Z","iopub.status.busy":"2023-04-15T18:38:21.448463Z","iopub.status.idle":"2023-04-15T18:40:09.479680Z","shell.execute_reply":"2023-04-15T18:40:09.478629Z","shell.execute_reply.started":"2023-04-15T18:38:21.451359Z"},"trusted":true},"outputs":[],"source":["s_train_dataset = SquadDataset(split='train', tokenizer=tokenizer, task_num=0)\n","s_val_dataset = SquadDataset(split='validation', tokenizer=tokenizer, task_num=0)\n","\n","r_train_dataset = RaceDataset(split='train', tokenizer=tokenizer, task_num=1)\n","r_val_dataset = RaceDataset(split='validation', tokenizer=tokenizer, task_num=1)\n","\n","b_train_dataset = BillsumDataset(split='train', tokenizer=tokenizer, task_num=2)\n","b_val_dataset = BillsumDataset(split='ca_test', tokenizer=tokenizer, task_num=2)\n","\n","trains = [s_train_dataset, r_train_dataset, b_train_dataset]\n","vals = [s_val_dataset, r_val_dataset, b_val_dataset]\n","\n","batch_size = 2\n","\n","train_loader = CircularDataLoader(trains, batch_size=batch_size)\n","val_loader = CircularDataLoader(vals, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:40:10.081930Z","iopub.status.busy":"2023-04-15T18:40:10.081627Z","iopub.status.idle":"2023-04-15T18:40:10.095716Z","shell.execute_reply":"2023-04-15T18:40:10.094645Z","shell.execute_reply.started":"2023-04-15T18:40:10.081903Z"},"trusted":true},"outputs":[],"source":["context = \"\"\"\n","Architecturally, the school has a Catholic character.\n","Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary.\n","Immediately in front of the Main Building and facing it,\n","is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\".\n","Next to the Main Building is the Basilica of the Sacred Heart.\n","Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.\n","It is a replica of the grotto at Lourdes,\n","France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.\n","At the end of the main drive (and in a direct line that connects through 3\n","statues and the Gold Dome), is a simple, modern stone statue of Mary.\n","\"\"\"\n","\n","tokenized_context = tokenizer(context, padding='max_length',\n","                               max_length=512, truncation=True, return_tensors='pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:40:10.100762Z","iopub.status.busy":"2023-04-15T18:40:10.100279Z","iopub.status.idle":"2023-04-15T18:40:10.119249Z","shell.execute_reply":"2023-04-15T18:40:10.117921Z","shell.execute_reply.started":"2023-04-15T18:40:10.100734Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class T5FineTuner(pl.LightningModule):\n","    def __init__(self, context, tokenizer):\n","        super().__init__()\n","        self.model = T5ForConditionalGeneration.from_pretrained('t5-small')\n","        self.context = context\n","        self.tokenizer = tokenizer\n","        \n","    def forward(self, input_ids, labels):\n","        return self.model(input_ids=input_ids,\n","                          labels=labels)\n","    \n","    def training_step(self, batch, batch_idx):\n","        input_ids = batch['input_ids']\n","        labels = batch['target_ids']\n","        \n","        loss = self(input_ids.cuda(), labels.cuda()).loss\n","        \n","        self.log('train_loss', loss)\n","        \n","        if batch_idx % 1000 == 0:\n","            print(self.generate_example())\n","            sep = '#' * 60\n","            print(sep)\n","        \n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        input_ids = batch['input_ids']\n","        labels = batch['target_ids']\n","        \n","        loss = self(input_ids.cuda(), labels.cuda()).loss\n","        \n","        self.log('val_loss', loss)\n","        return loss\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(self.parameters(), lr=2e-5)\n","    \n","    def generate_example(self):\n","        with torch.no_grad():\n","            input_ids = self.context['input_ids'][0]\n","            attention_mask = self.context['attention_mask'][0]\n","\n","            generated_ids = self.model.generate(input_ids=input_ids.unsqueeze(0).cuda(),\n","                                                attention_mask=attention_mask.unsqueeze(0).cuda(),\n","                                                max_length=64)\n","            generated_text = self.tokenizer.decode(generated_ids[0],\n","                                                   skip_special_tokens=True)\n","\n","        return generated_text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:40:10.122762Z","iopub.status.busy":"2023-04-15T18:40:10.122022Z","iopub.status.idle":"2023-04-15T18:40:10.151767Z","shell.execute_reply":"2023-04-15T18:40:10.150992Z","shell.execute_reply.started":"2023-04-15T18:40:10.122713Z"},"trusted":true},"outputs":[],"source":["class MultiTaskT5(pl.LightningModule):\n","    def __init__(self, task_dict, tokenized_context, tokenizer=None):\n","        super().__init__()\n","        self.task_dict = task_dict\n","        self.num_tasks = len(task_dict)\n","        self.context = tokenized_context\n","        \n","        self.tokenizer = tokenizer if tokenizer else T5Tokenizer.from_pretrained('t5-small')\n","\n","        self.model = T5ForConditionalGeneration.from_pretrained('t5-small')\n","        self.task_decoders = nn.ModuleList([copy.deepcopy(self.model.decoder)\n","                                            for _ in range(self.num_tasks)])\n","        \n","    def forward(self, input_ids, labels, task_num):\n","        self.model.decoder = self.task_decoders[task_num].cuda()\n","        return self.model(input_ids=input_ids,\n","                          labels=labels)\n","        \n","    def training_step(self, batch, batch_idx):\n","        input_ids = batch['input_ids']\n","        target_ids = batch['target_ids']\n","        task = batch['task'][0].item()\n","\n","        out = self.forward(input_ids=input_ids.cuda(),\n","                           labels=target_ids.cuda(),\n","                           task_num=task)\n","        loss = out.loss\n","        self.log(f'{self.task_dict[task]}_train_loss', loss, on_epoch=True, on_step=True)\n","        \n","        if batch_idx % 1000 == 0:\n","            for i, t in enumerate(self.generate_example()):\n","                print(self.task_dict[i], ':\\n', t, end='\\n\\n', sep='')\n","            sep = '#' * 60\n","            print(sep)\n","        \n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        input_ids = batch['input_ids']\n","        target_ids = batch['target_ids']\n","        task = batch['task'][0].item()\n","        \n","        out = self.forward(input_ids=input_ids.cuda(),\n","                           labels=target_ids.cuda(),\n","                           task_num=task)\n","        loss = out.loss\n","        self.log(f'{self.task_dict[task]}_val_loss', loss, on_epoch=True, on_step=False)\n","        \n","        return loss\n","        \n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(self.parameters(), lr=3e-5)\n","    \n","    def generate(self, input_ids, attention_mask, task_num, max_length=64):\n","        self.model.decoder = self.task_decoders[task_num]\n","        generated_ids = self.model.generate(input_ids=input_ids.unsqueeze(0).cuda(),\n","                                            attention_mask=attention_mask.unsqueeze(0).cuda(),\n","                                            max_length=max_length)\n","        return generated_ids\n","    \n","    def generate_example(self):\n","        with torch.no_grad():\n","            input_ids = self.context['input_ids'][0]\n","            attention_mask = self.context['attention_mask'][0]\n","            \n","            res = []\n","            for tn in range(self.num_tasks):\n","                generated_ids = self.generate(input_ids, attention_mask, tn)\n","                generated_text = self.tokenizer.decode(generated_ids[0],\n","                                                       skip_special_tokens=True)\n","                res.append(generated_text)\n","\n","        return res"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:40:10.153907Z","iopub.status.busy":"2023-04-15T18:40:10.152930Z","iopub.status.idle":"2023-04-15T18:40:10.165863Z","shell.execute_reply":"2023-04-15T18:40:10.165079Z","shell.execute_reply.started":"2023-04-15T18:40:10.153869Z"},"trusted":true},"outputs":[],"source":["# t5_fine_tuner = T5FineTuner(context=tokenized_context, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T18:46:20.839972Z","iopub.status.busy":"2023-04-15T18:46:20.839233Z","iopub.status.idle":"2023-04-15T18:46:23.790711Z","shell.execute_reply":"2023-04-15T18:46:23.789697Z","shell.execute_reply.started":"2023-04-15T18:46:20.839931Z"},"trusted":true},"outputs":[],"source":["task_dict = {\n","    0: 'question_gen',\n","    1: 'sentence_comp',\n","    2: 'summarization'\n","}\n","multi_task_t5 = MultiTaskT5.load_from_checkpoint('/kaggle/input/multi-task-t5/model.ckpt',\n","                                                 task_dict=task_dict, \n","                                                 tokenizer=tokenizer, \n","                                                 tokenized_context=tokenized_context).cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T13:47:48.065068Z","iopub.status.busy":"2023-04-14T13:47:48.064125Z","iopub.status.idle":"2023-04-14T13:48:20.197750Z","shell.execute_reply":"2023-04-14T13:48:20.196618Z","shell.execute_reply.started":"2023-04-14T13:47:48.065026Z"},"trusted":true},"outputs":[],"source":["checkpoint_callback = ModelCheckpoint(\n","    monitor='epoch',\n","    dirpath='/kaggle/working',\n","    filename='model',\n","    save_top_k=-1,\n","    mode='min'\n",")\n","\n","wandb_logger = pl.loggers.WandbLogger(project='question-generation', entity='questgen')\n","trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=3,\n","                     callbacks=[checkpoint_callback],\n","                     logger=wandb_logger)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T13:48:20.205824Z","iopub.status.busy":"2023-04-14T13:48:20.203462Z","iopub.status.idle":"2023-04-14T13:50:29.428348Z","shell.execute_reply":"2023-04-14T13:50:29.427193Z","shell.execute_reply.started":"2023-04-14T13:48:20.205772Z"},"trusted":true},"outputs":[],"source":["trainer.fit(multi_task_t5, train_loader, val_loader)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
